{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import essential libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "# drive.mount('/content/drive')\n",
    "# uploaded = files.upload()  # Upload all images manually from your local system\n",
    "DATASET_PATH = '/content/drive/MyDrive/Student-engagement-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories based on your dataset structure\n",
    "CATEGORIES = {\n",
    "    \"Engaged\": [\"confused\", \"engaged\", \"frustrated\"],\n",
    "    \"Not_engaged\": [\"bored\", \"drowsy\", \"looking_away\"]\n",
    "}\n",
    "\n",
    "IMG_SIZE = 70  # Resize images for uniformity\n",
    "DATASET_PATH = '/content/drive/MyDrive/Student-engagement-dataset'\n",
    "\n",
    "def load_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for main_category, subcategories in CATEGORIES.items():\n",
    "        for subcategory in subcategories:\n",
    "            category_path = os.path.join(DATASET_PATH, main_category, subcategory)\n",
    "            label = 1 if main_category == \"Engaged\" else 0\n",
    "\n",
    "            if not os.path.exists(category_path):\n",
    "                print(f\"Warning: Path does not exist - {category_path}\")\n",
    "                continue\n",
    "\n",
    "            image_count = 0\n",
    "            for img_filename in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_filename)\n",
    "\n",
    "                if not img_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img_array is None:\n",
    "                        print(f\"Warning: Could not read image - {img_path}\")\n",
    "                        continue\n",
    "\n",
    "                    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                    # Convert grayscale to RGB\n",
    "                    rgb_array = cv2.cvtColor(resized_array, cv2.COLOR_GRAY2RGB)\n",
    "                    data.append(rgb_array)\n",
    "                    labels.append(label)\n",
    "                    image_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "            print(f\"Processed {image_count} images in {category_path}\")\n",
    "\n",
    "    # Convert data to NumPy arrays and normalize pixel values\n",
    "    data = np.array(data) / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# Load data and split it into training and testing sets\n",
    "data, labels = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Optionally print some information\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name=\"engagement_model\"):\n",
    "    # Split training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Load pre-trained VGG16 model (excluding top layers)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    # Build the custom model\n",
    "    model = Sequential()\n",
    "    model.add(base_model)  # Add pre-trained VGG16 model\n",
    "    model.add(Flatten())  # Flatten the output from the VGG16 base model\n",
    "    model.add(Dense(512, activation='relu'))  # Add a dense layer with more units\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "    # Compile the model with a learning rate scheduler\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Learning rate scheduler to reduce learning rate when validation loss plateaus\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    # Early stopping with more patience\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with data augmentation\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "              epochs=50,  # Increased number of epochs\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save model to Google Drive\n",
    "    model_path = f'/content/drive/MyDrive/{model_name}.h5'\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Generate predictions and confusion matrix\n",
    "    y_pred = model.predict(X_test).flatten()  # Predictions as probabilities\n",
    "    y_pred_classes = np.round(y_pred).astype(int)  # Convert to binary class (0 or 1)\n",
    "\n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred_classes))\n",
    "\n",
    "    # Generate classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes, target_names=[\"Not Engaged\", \"Engaged\"], labels=[0, 1]))\n",
    "\n",
    "    # Generate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line for random guessing\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your data\n",
    "train_and_evaluate_model(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 70  # Resize images for uniformity\n",
    "\n",
    "# Prepare the image (resizing and normalization)\n",
    "def prepare_image(filepath):\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
    "\n",
    "# Model analysis function\n",
    "def analyze_images(model, test_folder):\n",
    "    times = []\n",
    "    attentionspan = []\n",
    "    start_index = None\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(test_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "    for idx, img_name in enumerate(image_files):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        try:\n",
    "            prediction = model.predict(prepare_image(img_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if prediction[0][0] >= 0.5:\n",
    "            if start_index is None:\n",
    "                start_index = idx\n",
    "        else:\n",
    "            if start_index is not None:\n",
    "                end_index = idx\n",
    "                times.append((start_index, end_index))\n",
    "                attentionspan.append(end_index - start_index)\n",
    "                start_index = None\n",
    "\n",
    "    average_attention_span = sum(attentionspan) / len(attentionspan) if attentionspan else 0\n",
    "    print(\"Attention times (indexes):\", times)\n",
    "    print(\"Average Attention Span (in frames):\", average_attention_span)\n",
    "    print(f\"Total periods of attention: {len(times)}\")\n",
    "\n",
    "# Load the model from the file\n",
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)  # Load the model from the path\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model_path = '/content/drive/MyDrive/engagement_model.h5'  # Path to your saved model\n",
    "test_images_path = '/content/drive/MyDrive/your_test_images'  # Path to your test images\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Analyze images with the trained model\n",
    "analyze_images(model, test_images_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
